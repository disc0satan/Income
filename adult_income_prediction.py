# -*- coding: utf-8 -*-
"""Adult Income Prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15dKR3UV_Of93Q_URRbrGeeNtt6l5Znlx

# **Project : Adult Income Prediction**

**Group 5**

**Md. Fardin Islam Mahi - 23301517**

**Jannatul Ferdous - 23201262**

# **1. Introduction**
The goal of this project is to analyze census data and predict whether an individual's income exceeds $50,000 per year. We utilize the "Adult Income Dataset" and apply Machine Learning algorithms to classify individuals based on demographics like age, education, and occupation.

**Motivation**: Understanding income distribution is crucial for economic planning and targeted marketing. By building a model that can accurately predict income levels based on available census data, organizations can better understand demographic trends and factors contributing to economic disparity.
"""

# Importing necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset
df = pd.read_csv('5.csv')
# Cleaning column names to remove extra spaces
df.columns = df.columns.str.strip()

print("Dataset loaded successfully.")

"""# **2. Dataset Description**
**a**. **Number of Features & Data Points**

First, we check the dimensions of our dataset to see how many samples (rows) and features (columns) we have available for training.
"""

# Checking the shape of the dataset
rows, cols = df.shape
print(f"Number of Data Points (Rows): {rows}")
print(f"Number of Features (Columns): {cols}")

"""**b. Types of Features**

Next, we examine the data types of each column. This helps us identify which columns are numerical (like Age) and which are categorical (like Education) so we can handle them correctly during pre-processing.
"""

# Displaying data types
print(df.info())

"""**c. Sample Data**

Let's look at the first few rows to understand what the raw data looks like.
"""

display(df.head())

"""# **3. Data Analysis (EDA)**

Following the EDA guidelines, we analyze the dataset's shape, feature types, statistics, and distributions. We also investigate the correlation between features and the target variable to understand their relationships.

**Feature Separation and Descriptive Statistics**


First, we separate the numerical and categorical features and look at their statistical summaries (count, mean, std, min, max, etc.) and distribution shape (variance, skewness).
"""

# 1. Shape of the dataset
print(f'Shape of the dataset is {df.shape}. This dataset contains {df.shape[0]} rows and {df.shape[1]} columns.\n')

# 2. Selecting numerical features
numerical_data = df.select_dtypes(include=['number'])
numerical_features = numerical_data.columns.tolist()

print(f'There are {len(numerical_features)} numerical features:')
print(numerical_features, '\n')

# 3. Selecting categorical features
categorical_data = df.select_dtypes(include=['object'])
categorical_features = categorical_data.columns.tolist()

print(f'There are {len(categorical_features)} categorical features:')
print(categorical_features, '\n')

# 4. Transposed stats for numerical features
print("--- Numerical Stats ---")
display(numerical_data.describe().T)

# 5. Transposed stats for categorical features
print("\n--- Categorical Stats ---")
display(categorical_data.describe().T)

# 6. Variance and Skewness
print("\n--- Variance ---")
print(numerical_data.var())
print("\n--- Skewness ---")
print(numerical_data.skew())

"""**Numerical Distributions (Histograms & Boxplots)**


We visualize the numerical data using histograms to see the frequency distribution and boxplots to detect outliers.
"""

import matplotlib.pyplot as plt
import seaborn as sns

# 1. Histograms for numerical features
numerical_data.hist(figsize=(12, 12), bins=20)
plt.suptitle('Histograms of Numerical Features')
plt.show()

# 2. Boxplots for numerical features
# Set up the figure size
plt.figure(figsize=(15, 20))

# Plot boxplots for each numerical feature
for i, col in enumerate(numerical_features, 1):
    plt.subplot(len(numerical_features), 1, i)
    sns.boxplot(x=df[col], color='skyblue')
    plt.title(f'Boxplot of {col}', fontsize=12)
    plt.tight_layout()

plt.show()

"""**Categorical Distributions**


We analyze the categorical features by counting unique values and plotting their distributions.
"""

# 1. Unique values count
print("--- Unique Values in Categorical Features ---")
print(categorical_data.nunique())

# 2. Bar plots for categorical features
for col in categorical_features:
    plt.figure(figsize=(10, 5))
    plt.title(f'Distribution of {col}')
    # We limit to top 10 categories for readability if there are many unique values
    df[col].value_counts().nlargest(10).sort_index().plot(kind='bar', rot=45, xlabel=col, ylabel='count')
    plt.show()

"""**Correlation Analysis**


We examine the relationships between numerical variables. To check the correlation with the target variable, we create a temporary encoded version of the target (since correlation requires numbers).
"""

# Creating a temporary copy to encode target for correlation analysis
df_corr = df.copy()
from sklearn.preprocessing import LabelEncoder
le_temp = LabelEncoder()
# Checking if target is categorical and encode it
if df_corr['target'].dtype == 'object':
    df_corr['target'] = le_temp.fit_transform(df_corr['target'])

# Recalculating numerical data including the encoded target
numerical_data_corr = df_corr.select_dtypes(include=['number'])

# 1. Correlation Matrix Heatmap
correlation_matrix = numerical_data_corr.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.3)
plt.title('Correlation Matrix Heatmap')
plt.show()

"""**Class Imbalance & Density Plots**


Finally, we check if the dataset is balanced (equal number of rich vs. poor) and visualize the density of numerical features.
"""

# 1. Check Imbalance in Target
class_counts = df['target'].value_counts()
total_samples = len(df)

# Create a dataframe for the imbalance stats
imbalance_df = pd.DataFrame({
    'outcome': class_counts.index,
    'count': class_counts.values,
    'percentage': (class_counts.values / total_samples) * 100
})

print("--- Class Imbalance Stats ---")
display(imbalance_df)

# Plot Imbalance
plt.figure(figsize=(6, 4))
sns.barplot(data=imbalance_df, x='outcome', y='percentage', palette='viridis')
plt.title('Class Imbalance in Target Variable')
plt.ylabel('Percentage')
plt.show()

# 2. Density Plots for Numerical Features
numerical_data.plot(kind='density', figsize=(14, 14), subplots=True, layout=(6, 2),
                    title="Density plot of Numerical features", sharex=False)
plt.tight_layout()
plt.show()

"""# **4. Dataset Pre-processing**

**Handling Null and Duplicate Values**

**Problem:** Real-world data often contains errors or missing values. In this dataset, missing values are denoted by a ?. Solution: We replace all ? with NaN (Not a Number) and then drop those rows to ensure model quality. We also remove duplicate rows to prevent the model from memorizing repeated data.
"""

# Replace ' ?' with NaN
df.replace(' ?', np.nan, inplace=True)

# Check for nulls before dropping
print(f"Missing values before cleaning:\n{df.isnull().sum().sum()}")

# Drop nulls and duplicates
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

print(f"New Shape after cleaning: {df.shape}")

"""**Encoding Categorical Values**

**Problem:** Machine Learning models require numerical input, but our data contains text (e.g., "Male", "Private"). Solution: We use Label Encoding to convert these unique string values into integers (e.g., Male=1, Female=0).
"""

from sklearn.preprocessing import LabelEncoder

# Separating Features (X) and Target (y) temporarily for encoding:
X = df.drop('target', axis=1)
y = df['target']

# Applying Label Encoding to all categorical columns:
label_encoders = {}
for column in X.select_dtypes(include=['object']).columns:
    le = LabelEncoder()
    X[column] = le.fit_transform(X[column])
    label_encoders[column] = le

# Encoding the Target variable:
le_target = LabelEncoder()
y = le_target.fit_transform(y)

print("Encoding Complete. Example of encoded data:")
display(X.head())

"""**Feature Scaling**

**Problem:** Features like Age (range 17-90) and Capital Gain (range 0-99999) have vastly different scales. This can cause the model to bias toward larger numbers. Solution: We use StandardScaler to normalize the data so that all features contribute equally to the result.
"""

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Splitting the data: 80% Training, 20% Testing
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

print("Data scaled and split into Train/Test sets.")

"""# **5. Model Training**

We will now train various models. We include both Supervised Learning (Neural Network, KNN, Decision Tree) and Unsupervised Learning (K-Means).

**K-Nearest Neighbors (KNN)**


**Description:** K-Nearest Neighbors (KNN) is a simple, instance-based learning algorithm. It classifies a new data point based on the majority class of its 'k' nearest neighbors.

**Optimization:** Choosing the right 'k' is critical. If 'k' is too small, the model is sensitive to noise (overfitting). If 'k' is too large, it smooths over patterns (underfitting).

**Approach:** Instead of guessing, we will loop through values of k from 1 to 20 and choose the one that gives the highest accuracy on our test set.
"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Lists to store results for plotting
k_values = range(1, 21)
accuracies = []

best_k = 0
best_score = 0
best_knn_model = None

print("Finding the best 'k' value...")

# Loop to find the best k
for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    score = accuracy_score(y_test, y_pred)
    accuracies.append(score)

    # Save the best model
    if score > best_score:
        best_score = score
        best_k = k
        best_knn_model = knn

print(f"\nBest 'k' found: {best_k}")
print(f"Highest Accuracy: {best_score*100:.2f}%")

# Plotting the K vs Accuracy Graph
plt.figure(figsize=(10, 5))
plt.plot(k_values, accuracies, marker='o', linestyle='-', color='blue')
plt.title('K-Value vs Accuracy')
plt.xlabel('Number of Neighbors (k)')
plt.ylabel('Accuracy')
plt.grid(True)
plt.show()

# Set our final KNN model to the best one we found
final_knn = best_knn_model

"""**Decision Tree Classifier**


**Description:** A Decision Tree is a flowchart-like structure where an internal node represents a feature, the branch represents a decision rule, and each leaf node represents the outcome.

**Configuration:** We use the 'entropy' criterion (Information Gain) to measure the quality of a split.
"""

from sklearn.tree import DecisionTreeClassifier

# Initialize Decision Tree
dt = DecisionTreeClassifier(criterion='entropy', random_state=42)

# Train the model
print("Training Decision Tree...")
dt.fit(X_train, y_train)

# Validate
dt_pred = dt.predict(X_test)
dt_acc = accuracy_score(y_test, dt_pred)
print(f"Decision Tree Accuracy: {dt_acc*100:.2f}%")

"""**Neural Network (Multi-Layer Perceptron)**


**Description:** A Multi-Layer Perceptron (MLP) is a class of feedforward artificial neural networks. It consists of at least three layers of nodes: an input layer, a hidden layer, and an output layer.

**Architecture:**

**Hidden Layers:** We use two hidden layers with 100 and 50 neurons respectively to capture complex patterns.

**Activation Function:** 'Relu' (Rectified Linear Unit) is used for hidden layers.

**Solver:** 'Adam' optimizer is used for weight adjustment.

**Max Iterations:** Set to 300 to allow sufficient training time.
"""

from sklearn.neural_network import MLPClassifier

# Initialize Neural Network
mlp = MLPClassifier(hidden_layer_sizes=(100, 50),
                    activation='relu',
                    solver='adam',
                    max_iter=300,
                    random_state=42)

# Train the model
print("Training Neural Network (this may take a moment)...")
mlp.fit(X_train, y_train)

# Validate
mlp_pred = mlp.predict(X_test)
mlp_acc = accuracy_score(y_test, mlp_pred)
print(f"Neural Network Accuracy: {mlp_acc*100:.2f}%")

# Visualize the Training Loss Curve
plt.figure(figsize=(8, 5))
plt.plot(mlp.loss_curve_, color='purple')
plt.title('Neural Network Training Loss Curve')
plt.xlabel('Iterations')
plt.ylabel('Loss')
plt.grid(True)
plt.show()

"""**Unsupervised Learning (K-Means Clustering)**


**Description:** K-Means is an unsupervised learning algorithm that groups data points into 'k' clusters based on feature similarity.

**Application:** Since we know our target has 2 classes (<=50K and >50K), we set n_clusters=2. We will check if the algorithm can naturally separate the income groups without being told the answers.
"""

from sklearn.cluster import KMeans

# Initialize K-Means
kmeans = KMeans(n_clusters=2, random_state=42, n_init=10)

# Train (Cluster) the data
print("Running K-Means Clustering...")
kmeans.fit(X_train)

# The labels assigned by K-Means (0 or 1)
cluster_labels = kmeans.labels_

print("Clustering Complete.")
print(f"Cluster Centers Shape: {kmeans.cluster_centers_.shape}")
print(f"First 20 Cluster Labels: {cluster_labels[:20]}")

# Visualize the clusters (using the first 2 features for 2D plot)
plt.figure(figsize=(8, 6))
plt.scatter(X_train[:, 0], X_train[:, 1], c=cluster_labels, cmap='viridis', alpha=0.5)
plt.title('K-Means Clustering (Visualized on first 2 features)')
plt.xlabel('Feature 1 (Scaled)')
plt.ylabel('Feature 2 (Scaled)')
plt.colorbar(label='Cluster Label')
plt.show()

"""# **6. Model Evaluation**

**Performance Metrics Table**


**Metrics Used:**

**Accuracy:** The percentage of correct predictions.

**F1-Score:** The harmonic mean of Precision and Recall (useful for imbalanced datasets).

**ROC-AUC:** The Area Under the Receiver Operating Characteristic Curve. A score of 1.0 is perfect; 0.5 is random guessing.

We will compute these metrics for all models and store them in a comparison table.
"""

from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score

# Dictionary of our trained models
models = {
    'KNN': final_knn,             # The best KNN model we found earlier
    'Decision Tree': dt,
    'Neural Network': mlp
}

# List to store results
results_list = []

print("Calculating metrics for all models...")

for name, model in models.items():
    # Make predictions
    y_pred = model.predict(X_test)

    # Try to get probabilities for ROC-AUC (some models need predict_proba)
    try:
        y_prob = model.predict_proba(X_test)[:, 1]
    except:
        y_prob = y_pred # Fallback if probability not available

    # Calculate metrics
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    auc = roc_auc_score(y_test, y_prob)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)

    results_list.append({
        'Model': name,
        'Accuracy': acc,
        'F1 Score': f1,
        'AUC Score': auc,
        'Precision': precision,
        'Recall': recall
    })

# Create DataFrame
results_df = pd.DataFrame(results_list)

# Display the sorted table (Best Accuracy on top)
print("\n--- Final Performance Table ---")
display(results_df.sort_values(by='Accuracy', ascending=False))

"""**Bar Chart Comparison**

A visual comparison of Accuracy and F1-Score helps us quickly identify the strongest model. Since our dataset is imbalanced, a high F1-score is just as important as high Accuracy.
"""

# Melt the dataframe for easier plotting with Seaborn
results_melted = results_df.melt(id_vars="Model", var_name="Metric", value_name="Score")
# Filter only Accuracy and F1 for the chart
results_melted = results_melted[results_melted['Metric'].isin(['Accuracy', 'F1 Score'])]

plt.figure(figsize=(10, 6))
sns.barplot(x='Model', y='Score', hue='Metric', data=results_melted, palette='viridis')

plt.title('Model Comparison: Accuracy vs F1 Score')
plt.ylim(0, 1.05) # Range from 0 to 1
plt.ylabel('Score')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.legend(loc='lower right')
plt.show()

"""**Confusion Matrices**

The Confusion Matrix provides a detailed breakdown of predictions:

**True Negatives (Top-Left):** Correctly predicted <=50K.

**True Positives (Bottom-Right):** Correctly predicted >50K.

**False Negatives (Bottom-Left):** Rich people incorrectly classified as poor (Critical Error).
"""

from sklearn.metrics import confusion_matrix

plt.figure(figsize=(18, 5))

for i, (name, model) in enumerate(models.items()):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)

    plt.subplot(1, 3, i+1)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)
    plt.title(f'{name} Confusion Matrix')
    plt.xlabel('Predicted Label')
    plt.ylabel('True Label')

plt.tight_layout()
plt.show()

"""**ROC - AUC Curves**

The ROC Curve illustrates the diagnostic ability of our classifiers.

The **X-axis** is the False Positive Rate (Risk of false alarm).

The **Y-axis** is the True Positive Rate (Sensitivity).

Curves closer to the **top-left** corner indicate better performance.
"""

from sklearn.metrics import roc_curve

plt.figure(figsize=(10, 8))

# Loop through models to plot their ROC curves
for name, model in models.items():
    # Get probabilities for the positive class (class 1)
    y_prob = model.predict_proba(X_test)[:, 1]

    # Calculate False Positive Rate and True Positive Rate
    fpr, tpr, _ = roc_curve(y_test, y_prob)

    # Get AUC score for label
    auc = roc_auc_score(y_test, y_prob)

    plt.plot(fpr, tpr, linewidth=2, label=f"{name} (AUC = {auc:.3f})")

# Plot diagonal line (Random Guessing)
plt.plot([0, 1], [0, 1], 'k--', linestyle='--', label='Random Guessing (AUC = 0.5)')

plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC - AUC Curve Comparison')
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.show()

"""# **Conclusion**


**Project Summary**
In this project, we analyzed the Adult Income dataset to predict income levels based on demographic features.

**Preprocessing:** We handled missing values, encoded categorical variables, and scaled features to ensure optimal model performance.

**Analysis:** EDA revealed a class imbalance (fewer people earning >50K) and strong correlations between Age/Education and Income.

**Modeling:** We trained KNN, Decision Tree, and Neural Network models, along with K-Means clustering.

**Final Verdict:** Best Model
Based on the evaluation metrics (Accuracy, F1-Score, and AUC), the Neural Network (MLP) is the best performing model.

Why? The Neural Network achieved the highest AUC score, indicating it is the best at distinguishing between the two income classes. It effectively captured the non-linear relationships between features like Education-Num, Age, and Hours-per-week.

**KNN Performance:** KNN performed well but was slightly less accurate than the Neural Network. The optimal k value helped reduce overfitting.

**Decision Tree:** While interpretable, the Decision Tree had a slightly lower F1-score, suggesting it struggled more with the class imbalance compared to the Neural Network.

**Future Improvements Hyperparameter Tuning:** We could use GridSearch to fine-tune the hidden layers of the Neural Network further.

**Handling Imbalance:** Techniques like SMOTE (Oversampling) could be applied to improve the recall for the minority class (>50K earners).
"""